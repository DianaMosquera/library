{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.lib.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing\n",
    "import scipy.signal\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audio has been recorded with a sampling rate of 44100.\n",
    "\n",
    "Let's load the data into the pandas dataframe with annotations. The dataset is small and it can fit into our RAM. This means, that every time we iterate over the dataset, we don't have to load every example from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.3 s, sys: 764 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "anno = pd.read_csv('data/annotations.csv')\n",
    "\n",
    "audio = []\n",
    "\n",
    "for _, row in anno.iterrows():\n",
    "    recording, _ = librosa.load(f'data/audio/{row.filename}', sr=None)\n",
    "    audio.append(recording)\n",
    "    \n",
    "anno['audio'] = audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shortest recording is just 1.04 seconds. The longest one is 178.68 second long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this, we will provide 4 options for this dataset:\n",
    "* sample random 1 second from each call for each example (the **sample** option)\n",
    "* cut each example into examples of 1 second duration (the **cut** option), this will produce some number of new examples, that will depend on the total length of recordings\n",
    "* pad each example to the longest example in the dataset (the **pad** option)\n",
    "* take just the 1 of each call from the beginning (the **first** option)\n",
    "\n",
    "Additionally, the classes are unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roodie    152\n",
       "Luke      117\n",
       "Mac        86\n",
       "Zoe        74\n",
       "Siggy      71\n",
       "Farley     52\n",
       "Freid      45\n",
       "Keri       42\n",
       "Louie      33\n",
       "Rudy       21\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide two versions of the dataset:\n",
    "* **unbalanced** (examples represented in line with counts in the raw dataset)\n",
    "* **balanced** (examples upsampled to count of the most frequently occuring class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleProcessor():\n",
    "    def __init__(self, example_length):\n",
    "        assert example_length in options.keys()\n",
    "        self.example_length = example_length\n",
    "    def __call__(self, example):\n",
    "        return options[self.example_length](example)\n",
    "    \n",
    "def first(example):\n",
    "    return example[:44100]\n",
    "\n",
    "def sample(example):\n",
    "    start_frame = np.random.randint(example.shape[0] - 44099)\n",
    "    return example[start_frame:start_frame+44100]\n",
    "\n",
    "def pad(example):\n",
    "    out = np.zeros((7879715))\n",
    "    out[:example.shape[0]] = example\n",
    "    return out    \n",
    "\n",
    "options = {\n",
    "    'first': first,\n",
    "    'sample': sample,\n",
    "    'pad': pad\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>context</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>sex</th>\n",
       "      <th>breed</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mac-3-A-3.aif</td>\n",
       "      <td>Mac</td>\n",
       "      <td>aggression</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>German shorthair pointer</td>\n",
       "      <td>[0.00012207031, 0.00064086914, 0.00010681152, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mac-3-P-3.aif</td>\n",
       "      <td>Mac</td>\n",
       "      <td>play</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>German shorthair pointer</td>\n",
       "      <td>[-0.0010375977, -0.0013427734, -0.0014038086, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac-2-P-2d.aif</td>\n",
       "      <td>Mac</td>\n",
       "      <td>play</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>German shorthair pointer</td>\n",
       "      <td>[0.00079345703, 0.00039672852, 0.00012207031, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mac-2-P-2b.aif</td>\n",
       "      <td>Mac</td>\n",
       "      <td>play</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>German shorthair pointer</td>\n",
       "      <td>[-0.00036621094, 0.00050354004, -0.0004119873,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mac-2-A-2a..aif</td>\n",
       "      <td>Mac</td>\n",
       "      <td>aggression</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>German shorthair pointer</td>\n",
       "      <td>[-7.6293945e-05, 0.00093078613, 0.00044250488,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename name     context  age  weight   sex  \\\n",
       "0    Mac-3-A-3.aif  Mac  aggression    5      34  male   \n",
       "1    Mac-3-P-3.aif  Mac        play    5      34  male   \n",
       "2   Mac-2-P-2d.aif  Mac        play    5      34  male   \n",
       "3   Mac-2-P-2b.aif  Mac        play    5      34  male   \n",
       "4  Mac-2-A-2a..aif  Mac  aggression    5      34  male   \n",
       "\n",
       "                      breed                                              audio  \n",
       "0  German shorthair pointer  [0.00012207031, 0.00064086914, 0.00010681152, ...  \n",
       "1  German shorthair pointer  [-0.0010375977, -0.0013427734, -0.0014038086, ...  \n",
       "2  German shorthair pointer  [0.00079345703, 0.00039672852, 0.00012207031, ...  \n",
       "3  German shorthair pointer  [-0.00036621094, 0.00050354004, -0.0004119873,...  \n",
       "4  German shorthair pointer  [-7.6293945e-05, 0.00093078613, 0.00044250488,...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 targets you can pick from: `name`, `context`, `age`, `weight`, `sex` and `breed`. Weight and age are continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'age'\n",
    "\n",
    "if target_name in ['name', 'context', 'sex', 'breed']:\n",
    "    target_type = 'label' \n",
    "else:\n",
    "    target_type = 'continous'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row2Target():\n",
    "    def __init__(self):\n",
    "        self.label2idx = {label:i for i, label in enumerate(anno[target_name].unique())}\n",
    "        \n",
    "    def __call__(self, row):\n",
    "        if target_type == 'continous':\n",
    "            return row[target_name]\n",
    "        else:\n",
    "            return self.label2idx[row[target_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2t = Row2Target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'first'\n",
    "\n",
    "if example == 'cut':\n",
    "    cls = []\n",
    "    audio = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        while True:\n",
    "            if row.audio.shape[0] < 44100: break\n",
    "            cls.append(row[target_name])\n",
    "            audio.append(row.audio[:44100])\n",
    "            row.audio = row.audio[44100:]\n",
    "    df = pd.DataFrame({target_name: cls, 'audio': audio})\n",
    "    example = 'first'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, example=example, classes='unbalanced'):\n",
    "        self.examples = df\n",
    "        self.example_processor = ExampleProcessor(example)\n",
    "        \n",
    "        assert classes in ['balanced', 'unbalanced']\n",
    "        if classes=='balanced':\n",
    "            max_examples = self.examples[target_name].value_counts().iloc[0]\n",
    "            for grp in self.examples.groupby(target_name):\n",
    "                example_count = self.examples[self.examples[target_name] == grp[0]].shape[0]\n",
    "                while example_count < max_examples:\n",
    "                    self.examples = self.examples.append(self.examples[self.examples[target_name] == grp[0]][:max_examples-example_count])\n",
    "                    example_count = self.examples[self.examples[target_name] == grp[0]].shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples.iloc[index]\n",
    "        x = self.example_processor(example.audio)\n",
    "        y = r2t(example)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.examples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     248\n",
       "12    152\n",
       "11     92\n",
       "7      74\n",
       "3      52\n",
       "4      42\n",
       "2      33\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno[target_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(anno[:600], example='first', classes='balanced')\n",
    "valid_ds = Dataset(anno[600:], example='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    155\n",
       "11    155\n",
       "7     155\n",
       "5     155\n",
       "4     155\n",
       "3     155\n",
       "2     155\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.examples[target_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=multiprocessing.cpu_count()-1\n",
    ")\n",
    "\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    dataset=valid_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=multiprocessing.cpu_count()-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dl: pass\n",
    "for batch in valid_dl: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([29, 44100]), torch.Size([29]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape, batch[1].shape # we are on the final batch, there were not enough examples to fill it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693, 8)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
