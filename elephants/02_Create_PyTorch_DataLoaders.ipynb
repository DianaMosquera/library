{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use vanilla `PyTorch`. We will convert audio to spectrograms and codenames to idices to be used as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.lib.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing\n",
    "import scipy.signal\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = pd.read_csv('data/annotations.csv')\n",
    "srs = []\n",
    "for _, row in anno.iterrows():\n",
    "    recording, sr = librosa.load(f'data/audio/{row.SndFile}.wav', sr=None)\n",
    "    srs.append(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2000, 3012, 22099, 43956, 48000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(srs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files have been recorded with sample rates varying from 2kHz to 48kHz. Let's downsample all the files to 2kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = pd.read_csv('data/annotations.csv')\n",
    "\n",
    "audio = []\n",
    "\n",
    "for _, row in anno.iterrows():\n",
    "    recording, _ = librosa.load(f'data/audio/{row.SndFile}.wav', sr=2000)\n",
    "    audio.append(recording[:5000]) # let's take just the first 2.5 seconds of audio\n",
    "    \n",
    "anno['audio'] = audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the audio stored in our pandas dataframe as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Tape</th>\n",
       "      <th>ElapsedTime</th>\n",
       "      <th>Type</th>\n",
       "      <th>ContextType</th>\n",
       "      <th>QR1</th>\n",
       "      <th>AgeCaller</th>\n",
       "      <th>AgeClassCaller</th>\n",
       "      <th>SexCaller</th>\n",
       "      <th>Callers</th>\n",
       "      <th>QR2</th>\n",
       "      <th>Meters</th>\n",
       "      <th>Directed to</th>\n",
       "      <th>FieldNotes</th>\n",
       "      <th>SndFile</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>rumble</td>\n",
       "      <td>lets go</td>\n",
       "      <td>A</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Echo</td>\n",
       "      <td>A</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>note that she give sharp ear flap first - this...</td>\n",
       "      <td>B0301552</td>\n",
       "      <td>[0.0, 0.0, -9.1552734e-05, -0.00079345703, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2708.0</td>\n",
       "      <td>rumble</td>\n",
       "      <td>female chorus</td>\n",
       "      <td>A</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Echo</td>\n",
       "      <td>A</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as tested by Masaku; and another rumble here ...</td>\n",
       "      <td>B0902708</td>\n",
       "      <td>[0.0, 0.0, 9.1552734e-05, 0.00079345703, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>rumble</td>\n",
       "      <td>cadenced</td>\n",
       "      <td>A</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Echo</td>\n",
       "      <td>A</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2002134</td>\n",
       "      <td>[-0.001953125, 0.0009765625, 0.0014648438, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>rumble</td>\n",
       "      <td>cadenced</td>\n",
       "      <td>A</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Echo</td>\n",
       "      <td>A</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo is in the lead facing OTO</td>\n",
       "      <td>B2002222</td>\n",
       "      <td>[0.000579834, 0.0010681152, -0.00039672852, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2331.0</td>\n",
       "      <td>rumble</td>\n",
       "      <td>cadenced</td>\n",
       "      <td>A</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Echo</td>\n",
       "      <td>A</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2002331</td>\n",
       "      <td>[0.0132751465, 0.012298584, 0.0093688965, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Tape  ElapsedTime    Type    ContextType QR1  AgeCaller  \\\n",
       "0  1999.0   3.0       1552.0  rumble        lets go   A       54.0   \n",
       "1  1999.0   9.0       2708.0  rumble  female chorus   A       54.0   \n",
       "2  1999.0  20.0       2134.0  rumble       cadenced   A       54.0   \n",
       "3  1999.0  20.0       2222.0  rumble       cadenced   A       54.0   \n",
       "4  1999.0  20.0       2331.0  rumble       cadenced   A       54.0   \n",
       "\n",
       "  AgeClassCaller SexCaller Callers QR2  Meters Directed to  \\\n",
       "0              5    Female    Echo   A    15.0         NaN   \n",
       "1              5    Female    Echo   A    10.0         NaN   \n",
       "2              5    Female    Echo   A    20.0         NaN   \n",
       "3              5    Female    Echo   A    20.0         NaN   \n",
       "4              5    Female    Echo   A    40.0         NaN   \n",
       "\n",
       "                                          FieldNotes   SndFile  \\\n",
       "0  note that she give sharp ear flap first - this...  B0301552   \n",
       "1   as tested by Masaku; and another rumble here ...  B0902708   \n",
       "2                                                NaN  B2002134   \n",
       "3                     Echo is in the lead facing OTO  B2002222   \n",
       "4                                                NaN  B2002331   \n",
       "\n",
       "                                               audio  \n",
       "0  [0.0, 0.0, -9.1552734e-05, -0.00079345703, -0....  \n",
       "1  [0.0, 0.0, 9.1552734e-05, 0.00079345703, 0.003...  \n",
       "2  [-0.001953125, 0.0009765625, 0.0014648438, 0.0...  \n",
       "3  [0.000579834, 0.0010681152, -0.00039672852, 0....  \n",
       "4  [0.0132751465, 0.012298584, 0.0093688965, 0.01...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the modified annotation file that now includes audio so that we can easily access it from other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno.to_pickle('data/anno_with_audio.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we need to do for each of the examples:\n",
    "* convert the audio to a spectrogram\n",
    "* assign label expressed as an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec = scipy.signal.spectrogram(anno.loc[0, 'audio'])[2]\n",
    "plt.imshow(spec);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now develop a way of representing labels as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callers = anno['Callers'].unique().tolist()\n",
    "\n",
    "caller2idx = {caller: idx for idx, caller in enumerate(callers)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the components in place, let's work on our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.examples = df\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples.iloc[index]\n",
    "        x = scipy.signal.spectrogram(anno.loc[0, 'audio'])[2]\n",
    "        y = caller2idx[example['Callers']]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.examples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = anno.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(shuffled.iloc[:250])\n",
    "valid_ds = Dataset(shuffled.iloc[250:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now construct the dataloaders to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=multiprocessing.cpu_count()-1\n",
    ")\n",
    "\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    dataset=valid_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=multiprocessing.cpu_count()-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dl: pass\n",
    "for batch in valid_dl: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 129, 22]), torch.Size([32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape, batch[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
